{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2LmLTREBf5ng",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LRmPPJegovBe",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_lyrics_corpus(dataset, field):\n",
    "  # Remove all other punctuation\n",
    "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "  # Make it lowercase\n",
    "  dataset[field] = dataset[field].str.lower()\n",
    "  # Make it one long string to split by line\n",
    "  lyrics = dataset[field].str.cat()\n",
    "  corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "  for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "  corpus = [l for l in corpus if l != '']\n",
    "\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Get the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Bf5FVHfganK",
    "outputId": "122f1276-3342-4e18-d997-1a01cefbd230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\.keras\\datasets\\songdata.csv\n"
     ]
    }
   ],
   "source": [
    "path = tf.keras.utils.get_file('songdata.csv', \n",
    "                               'https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8')\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read the dataset from csv - this time with 250 songs \n",
    "dataset = pd.read_csv(path, dtype=str)[:250]\n",
    "# Create the corpus using the 'text' column containing lyrics\n",
    "corpus = create_lyrics_corpus(dataset, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Tokenize the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the corpus\n",
    "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
    "total_words = tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIGedF3XjHj4",
    "lines_to_next_cell": 2,
    "outputId": "357e4814-b9ce-44be-f0db-8b87295cbe6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# There should be a lot more words now\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Create n-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kkLAf3HmkPSo"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tsequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences for equal input length \n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : X and y - Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "X = sequences[:,:-1]\n",
    "y_label = sequences[:,-1]\n",
    "# One-hot encode the labels\n",
    "y = tf.keras.utils.to_categorical(y_label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Step 6 : Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nHOp6uWlP_P",
    "outputId": "c3861729-7d63-483c-ad03-52b5af12c8ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 5.9802 - accuracy: 0.0463\n",
      "Epoch 2/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 5.6712 - accuracy: 0.0507\n",
      "Epoch 3/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 5.4987 - accuracy: 0.0621\n",
      "Epoch 4/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 5.3391 - accuracy: 0.0853\n",
      "Epoch 5/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 5.2055 - accuracy: 0.1012\n",
      "Epoch 6/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 5.0699 - accuracy: 0.1204\n",
      "Epoch 7/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.9368 - accuracy: 0.1350\n",
      "Epoch 8/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.8126 - accuracy: 0.1482\n",
      "Epoch 9/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.6809 - accuracy: 0.1614\n",
      "Epoch 10/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.5376 - accuracy: 0.1746\n",
      "Epoch 11/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.4081 - accuracy: 0.1904\n",
      "Epoch 12/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.2970 - accuracy: 0.2010\n",
      "Epoch 13/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.2007 - accuracy: 0.2124\n",
      "Epoch 14/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.1103 - accuracy: 0.2230\n",
      "Epoch 15/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 4.0355 - accuracy: 0.2336\n",
      "Epoch 16/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.9686 - accuracy: 0.2409\n",
      "Epoch 17/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.9065 - accuracy: 0.2498\n",
      "Epoch 18/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 3.8469 - accuracy: 0.2561\n",
      "Epoch 19/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.7929 - accuracy: 0.2642\n",
      "Epoch 20/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.7394 - accuracy: 0.2736\n",
      "Epoch 21/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.6923 - accuracy: 0.2797\n",
      "Epoch 22/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.6449 - accuracy: 0.2850\n",
      "Epoch 23/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.6026 - accuracy: 0.2916\n",
      "Epoch 24/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.5614 - accuracy: 0.2962\n",
      "Epoch 25/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.5190 - accuracy: 0.30200s - loss: 3.5181 - accuracy\n",
      "Epoch 26/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.4833 - accuracy: 0.3106\n",
      "Epoch 27/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.4538 - accuracy: 0.31160s - loss: 3.4551 - ac\n",
      "Epoch 28/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.4215 - accuracy: 0.3176\n",
      "Epoch 29/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.3782 - accuracy: 0.3235\n",
      "Epoch 30/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.3470 - accuracy: 0.3297\n",
      "Epoch 31/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.3154 - accuracy: 0.3342\n",
      "Epoch 32/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.2863 - accuracy: 0.3376\n",
      "Epoch 33/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.2496 - accuracy: 0.3446\n",
      "Epoch 34/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.2236 - accuracy: 0.3472\n",
      "Epoch 35/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.1961 - accuracy: 0.3529\n",
      "Epoch 36/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.1772 - accuracy: 0.3544\n",
      "Epoch 37/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.1573 - accuracy: 0.3581\n",
      "Epoch 38/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.1226 - accuracy: 0.3612\n",
      "Epoch 39/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 3.0981 - accuracy: 0.3670\n",
      "Epoch 40/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 3.0742 - accuracy: 0.3709\n",
      "Epoch 41/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 3.0536 - accuracy: 0.3721\n",
      "Epoch 42/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 3.0386 - accuracy: 0.3754\n",
      "Epoch 43/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 3.0041 - accuracy: 0.3817\n",
      "Epoch 44/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.9896 - accuracy: 0.3826\n",
      "Epoch 45/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.9730 - accuracy: 0.3847\n",
      "Epoch 46/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.9442 - accuracy: 0.3896\n",
      "Epoch 47/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.9311 - accuracy: 0.3931\n",
      "Epoch 48/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.9069 - accuracy: 0.3969\n",
      "Epoch 49/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.9029 - accuracy: 0.3984\n",
      "Epoch 50/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.8791 - accuracy: 0.4003\n",
      "Epoch 51/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.8567 - accuracy: 0.4060\n",
      "Epoch 52/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.8472 - accuracy: 0.4060\n",
      "Epoch 53/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.8281 - accuracy: 0.4108\n",
      "Epoch 54/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.8106 - accuracy: 0.4128\n",
      "Epoch 55/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.7954 - accuracy: 0.4161\n",
      "Epoch 56/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.7971 - accuracy: 0.4178\n",
      "Epoch 57/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.7655 - accuracy: 0.4208\n",
      "Epoch 58/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.7554 - accuracy: 0.4237\n",
      "Epoch 59/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.7335 - accuracy: 0.4268\n",
      "Epoch 60/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.7180 - accuracy: 0.4300\n",
      "Epoch 61/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.7264 - accuracy: 0.4294\n",
      "Epoch 62/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.6977 - accuracy: 0.4342\n",
      "Epoch 63/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.6828 - accuracy: 0.4363\n",
      "Epoch 64/100\n",
      "1480/1480 [==============================] - 16s 11ms/step - loss: 2.6679 - accuracy: 0.4389\n",
      "Epoch 65/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6608 - accuracy: 0.4408\n",
      "Epoch 66/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.6465 - accuracy: 0.4442\n",
      "Epoch 67/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.6362 - accuracy: 0.4458\n",
      "Epoch 68/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.6204 - accuracy: 0.4487\n",
      "Epoch 69/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.6049 - accuracy: 0.4503\n",
      "Epoch 70/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5972 - accuracy: 0.4530TA: 0s - loss: 2.5971 - accuracy\n",
      "Epoch 71/100\n",
      "1480/1480 [==============================] - 10818s 7s/step - loss: 2.5888 - accuracy: 0.4559 6:33 -\n",
      "Epoch 72/100\n",
      "1480/1480 [==============================] - 21398s 14s/step - loss: 2.5710 - accuracy: 0.4578 9:08 - loss\n",
      "Epoch 73/100\n",
      "1480/1480 [==============================] - 23s 15ms/step - loss: 2.5603 - accuracy: 0.4590\n",
      "Epoch 74/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5541 - accuracy: 0.4602\n",
      "Epoch 75/100\n",
      "1480/1480 [==============================] - 20s 14ms/step - loss: 2.5432 - accuracy: 0.4649\n",
      "Epoch 76/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.5299 - accuracy: 0.4665\n",
      "Epoch 77/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5218 - accuracy: 0.4680\n",
      "Epoch 78/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5121 - accuracy: 0.4684\n",
      "Epoch 79/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.5078 - accuracy: 0.4681\n",
      "Epoch 80/100\n",
      "1480/1480 [==============================] - 19s 13ms/step - loss: 2.4991 - accuracy: 0.4699\n",
      "Epoch 81/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.4897 - accuracy: 0.4718\n",
      "Epoch 82/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.4902 - accuracy: 0.4710\n",
      "Epoch 83/100\n",
      "1480/1480 [==============================] - 18s 12ms/step - loss: 2.4852 - accuracy: 0.4718\n",
      "Epoch 84/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.4653 - accuracy: 0.4786\n",
      "Epoch 85/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.4500 - accuracy: 0.4806\n",
      "Epoch 86/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4402 - accuracy: 0.4820\n",
      "Epoch 87/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4360 - accuracy: 0.4832\n",
      "Epoch 88/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.4287 - accuracy: 0.4831\n",
      "Epoch 89/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.4261 - accuracy: 0.4804\n",
      "Epoch 90/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.4126 - accuracy: 0.4886\n",
      "Epoch 91/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3984 - accuracy: 0.4887\n",
      "Epoch 92/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3926 - accuracy: 0.49060s - los\n",
      "Epoch 93/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3867 - accuracy: 0.4915\n",
      "Epoch 94/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3858 - accuracy: 0.4926\n",
      "Epoch 95/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3724 - accuracy: 0.4928\n",
      "Epoch 96/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3706 - accuracy: 0.4917\n",
      "Epoch 97/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3596 - accuracy: 0.4952\n",
      "Epoch 98/100\n",
      "1480/1480 [==============================] - 17s 11ms/step - loss: 2.3480 - accuracy: 0.4974\n",
      "Epoch 99/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3372 - accuracy: 0.5005\n",
      "Epoch 100/100\n",
      "1480/1480 [==============================] - 17s 12ms/step - loss: 2.3396 - accuracy: 0.5002\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "rOqmmarvlSLh",
    "outputId": "dfcb481d-f4a1-4380-aa8a-1be88f22cad7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time around, we should be able to get a more interesting output with less repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P96oVMk3lU7y",
    "outputId": "2df58e73-cfb9-41ee-f619-ddd37df34da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills a little longer yeah you do alright pick a little bit that sun grow doublecross inside cutie to taught christmas of hoy more tomorrow other colors changing sigh single line while lala im gonna dance or somebody old goin phone on letters up for each other side hour chance in space back joy single side with forever live sister hang nile woke excite single dum shoes phone heh speaking gold ancient high upon gold result of hesitation of hesitation of fights phone shove her part phone other dark deep dark shove waterloo ground seeing can use forever shine to her\n"
     ]
    }
   ],
   "source": [
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Step : Add Randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upgJKV8_oRU9"
   },
   "source": [
    "Varying the Possible Outputs\n",
    "\n",
    "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
    "\n",
    "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the method with just the first word after the seed text\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZe9gaJeoGVP",
    "outputId": "52c8abf6-3387-4a40-a319-a488b640c163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
    "                             p=predicted_probs)\n",
    "# Running this cell multiple times should get you some variance in output\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills a man in the rough its so my girl goes worse right promises phone track the children devotion bring misunderstood ground weave shine yeah up be my day with us to show he eternal ways get gone too far together light phone im a way from sunny time single other side heavens wish girls single tiger fault difference walked high what fuckin bay sorrow track emotion regrets diddle diggin diddle nearly kisses hardly plan march chasing phone heh beats ballerina phone on that night if it yes he got so nothin nothin nothin to me it doesnt share of love\n"
     ]
    }
   ],
   "source": [
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "  predicted_probs = model.predict(token_list)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "formats": "ipynb,py:nomarker"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
