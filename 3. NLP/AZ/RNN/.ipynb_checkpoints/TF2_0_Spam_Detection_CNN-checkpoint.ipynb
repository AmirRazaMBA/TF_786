{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZjhmiCi66lb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "9Shv7Pyi9iON",
    "outputId": "7dd36f72-885c-41e2-b5f1-af5e3e2ac4a1"
   },
   "outputs": [],
   "source": [
    "# Unfortunately this URL doesn't work directly with pd.read_csv\n",
    "!wget -nc https://lazyprogrammer.me/course_files/spam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2X3TBMqM7HBT"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keaeAYpz9rOm"
   },
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNTZG5OW9u2b"
   },
   "outputs": [],
   "source": [
    "# rename columns to something better\n",
    "df.columns = ['labels', 'data']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbEYhaMz9zkB"
   },
   "outputs": [],
   "source": [
    "# create binary labels\n",
    "df['b_labels'] = df['labels'].map({'ham': 0, 'spam': 1})\n",
    "Y = df['b_labels'].values\n",
    "\n",
    "# split up the data\n",
    "df_train, df_test, Ytrain, Ytest = train_test_split(df['data'], Y, test_size=0.33)\n",
    "\n",
    "# Convert sentences to sequences\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(df_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(df_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(df_test)\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "V = len(word2idx)\n",
    "print('Found %s unique tokens.' % V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NP1W8Cf9-cPo",
    "outputId": "401b1d3c-8af0-4997-8904-9acc33a4a991"
   },
   "outputs": [],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "data_train = pad_sequences(sequences_train)\n",
    "print('Shape of data train tensor:', data_train.shape)\n",
    "\n",
    "# get sequence length\n",
    "T = data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "b6He4SKO-qci",
    "outputId": "4fb6f704-871a-4178-899b-9161977acbb9"
   },
   "outputs": [],
   "source": [
    "data_test = pad_sequences(sequences_test, maxlen=T)\n",
    "print('Shape of data test tensor:', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFnA0eiI-2BM"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "# We get to choose embedding dimensionality\n",
    "D = 20\n",
    "\n",
    "# Note: we actually want to the size of the embedding to (V + 1) x D,\n",
    "# because the first index starts from 1 and not 0.\n",
    "# Thus, if the final index of the embedding matrix is V,\n",
    "# then it actually must have size V + 1.\n",
    "\n",
    "i = Input(shape=(T,))\n",
    "x = Embedding(V + 1, D)(i)\n",
    "x = Conv1D(32, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(i, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "DyBTI9wr_cvG",
    "outputId": "c01ba55b-372d-4939-e219-ed854511c13d"
   },
   "outputs": [],
   "source": [
    "# Compile and fit\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit(\n",
    "  data_train,\n",
    "  Ytrain,\n",
    "  epochs=5,\n",
    "  validation_data=(data_test, Ytest)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "j636obn9CE7A",
    "outputId": "aab6a6fe-20dd-4685-db69-79a56ef6d826"
   },
   "outputs": [],
   "source": [
    "# Plot loss per iteration\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "y4xIBkKjC1RP",
    "outputId": "a3cc829f-c58a-4eb5-c225-173d8603b00d"
   },
   "outputs": [],
   "source": [
    "# Plot accuracy per iteration\n",
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF2.0 Spam Detection CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
